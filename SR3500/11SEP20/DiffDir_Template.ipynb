{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for Diffuse/Direct - Mullion - 11SEP20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "This workflow is designed such that you should only need to edit information in the first cell below.\n",
    "\n",
    "The workflow assumes that diffuse/direct measurements have been taken with either 6 or 8 spectra for each measurement. If any other number of spectra is found, all of them will be ignored. It is assumed that with 6 spectra, the oder of measurement is Direct, Helper, Shade, with two spectra for each part. If there are 8 spectra, it is assumed that the last two are Helper.\n",
    "    \n",
    "### Input and Output directories\n",
    "Specify input directory as 'indir' and output directory as 'outdir'. Remember to include trailing slash (/) in path name.\n",
    "\n",
    "### Field data information\n",
    "The \"field_data\" list should contain basic information on the location and date of the diffuse/direct measurements. The first entry is the field site three-letter-acronym (eg \"MUL\" for Mullion), the second entry is the date in DDMMMYY format.\n",
    "\n",
    "### Prefix list\n",
    "'PreList' contains substrings that are searched for in order to identify diffuse/direct spectra. If your spectral\n",
    "files contain any of these, then the workflow will pick them up. Other substrings can be added to this list.\n",
    "\n",
    "### Suffix\n",
    "Since it is possible that not all ASD spectra files have the same filename suffix, this is manually entered as \"asd.irr.txt\". Pay close attention to the full stops in this string. ie. \".asd.irr.txt\" will not work.\n",
    "\n",
    "\n",
    "Once you have all of the fields in the first cell correctly filled out, you can click on \"Kernel\" -> \"Restart & Run All\". Scroll down to the bottom to see results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Start a clock to time the workflow\n",
    "#\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "#\n",
    "# Specify input and output directories below\n",
    "#\n",
    "#indir = '/g/data/up71/projects/CalVal_Phase2/SR3500/11SEP20/RAW_DATA/ASD_DATA/direct_diffuse/ALL/'\n",
    "indir = '/g/data/u46/users/gtb547/cal_val/in_spectra/Mullion/Mull_13_2020_9_nov_s2b/atmosphere/direct_diffuse/end/'\n",
    "outdir = '/g/data/up71/projects/CalVal_Phase2/SR3500/11SEP20/PNGS/TMP/'\n",
    "\n",
    "#\n",
    "# Specify an input image to overplot on spectra\n",
    "#\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cbook import get_sample_data\n",
    "im = plt.imread(get_sample_data('/g/data/u46/users/gtb547/cal_val/in_spectra/Mullion/Mull_12_2020_11_sept_s2b/photos/20200911_102803.jpg'))\n",
    "\n",
    "#\n",
    "# Fill out field_data below. It is in the format: 'Field Site Short Name', 'Date'.\n",
    "#\n",
    "field_data = ['MUL', '11SEP20']\n",
    "\n",
    "#\n",
    "# List of prefixes to pattern match DD files on\n",
    "#\n",
    "PreList = ['dd', 'diffdir', 'dif_dir', 'irrads', 'direct_diffuse']\n",
    "\n",
    "#\n",
    "# Assumed suffix for spectral files is defined below\n",
    "#\n",
    "#suffix = 'asd.irr.txt'\n",
    "suffix = '.txt'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import plotting packages and set up png outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "import datacube\n",
    "import sys, os, shutil, glob, subprocess\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "#\n",
    "# Use notebook format\n",
    "# Set default font size for all plots\n",
    "# Set saved figure dpi to high quality\n",
    "#\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "matplotlib.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "#\n",
    "# Remove old files in output directory and create a new one\n",
    "#\n",
    "directory = os.path.dirname(outdir)\n",
    "if os.path.exists(directory):\n",
    "    shutil.rmtree(directory)\n",
    "os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up colours used for plotting spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "# Colours used for plotting multi-coloured Lines\n",
    "#\n",
    "colpac=[['#770000', '#FF0000'],\n",
    "        ['#007700', '#00FF00'],\n",
    "        ['#000077', '#0000FF'],\n",
    "        ['#777700', '#FFFF00'],\n",
    "        ['#007777', '#00FFFF'],\n",
    "        ['#770077', '#FF00FF']]\n",
    "\n",
    "\n",
    "#\n",
    "# Start Figure numbering at 1\n",
    "#\n",
    "fignum = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following cell was originally \"LoadData.py\", but brought internally so the notebook doesn't depend on anything externally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                                                                             #\n",
    "# Action functions are defined to retrieve specific parts of the header for   #\n",
    "# each spectrum. These functions are used in extract_metadata.                #\n",
    "#                                                                             #\n",
    "###############################################################################\n",
    "\n",
    "# Instrument Number\n",
    "def action1(l):\n",
    "    return l[27:34]\n",
    "\n",
    "# Datetime of spectrum\n",
    "def action2(l):\n",
    "    return l[16:38]\n",
    "\n",
    "# SWIR1 gain\n",
    "def action3(l):\n",
    "    return l[15:33]\n",
    "\n",
    "# SWIR2 gain\n",
    "def action4(l):\n",
    "    return l[15:33]\n",
    "\n",
    "# GPS Latitude in decimal degrees\n",
    "def action5(l):\n",
    "    try:\n",
    "        lat = float(l[17:20])-float(l[20:27])/60\n",
    "    except ValueError:\n",
    "        lat = 0\n",
    "    print('Lat = ', lat)\n",
    "    return lat\n",
    "\n",
    "# GPS Longitude in decimal degrees\n",
    "def action6(l):\n",
    "    try:\n",
    "        lon = float(l[19:22])+float(l[22:30])/60\n",
    "    except ValueError:\n",
    "        lon = 0\n",
    "    print('Lon = ', lon)\n",
    "    return lon\n",
    "\n",
    "#\n",
    "# Based on action functions defined above, extract header metadata from\n",
    "# a file.\n",
    "#\n",
    "def extract_metadata(filename):\n",
    "    strings = {\n",
    "        'instrument number': action1,\n",
    "        'Spectrum saved': action2,\n",
    "        'GPS-Latitude': action5,\n",
    "        'GPS-Longitude': action6\n",
    "    }\n",
    "\n",
    "    with open(filename) as file:\n",
    "        list_of_actions = []\n",
    "        for line in file:\n",
    "            for search, action in strings.items():\n",
    "                if search in line:\n",
    "                    list_of_actions.append(action(line))\n",
    "        return list_of_actions\n",
    "\n",
    "#\n",
    "### Extract spectrum and header information from a spectrum file. \n",
    "### Create a Pandas dataframe with the result.\n",
    "#\n",
    "def load_spectrum_to_df(infile, i):\n",
    "    \n",
    "    p1 = subprocess.Popen([\"grep\", \"-an\", \"^Wavelength\", infile], stdout=subprocess.PIPE)\n",
    "    p2 = subprocess.Popen([\"cut\", \"-d:\", \"-f\", \"1\"], stdin=p1.stdout, stdout=subprocess.PIPE)\n",
    "    p1.stdout.close()  # Allow p1 to receive a SIGPIPE if p2 exits.\n",
    "    fdl,err = p2.communicate()\n",
    "    firstDataLine = int(fdl)-1\n",
    "\n",
    "    inst, date_str, lat, lon = extract_metadata(infile)\n",
    "\n",
    "    date_saved = datetime.strptime(date_str, '%m/%d/%Y at %H:%M:%S')\n",
    "    \n",
    "    df = pd.read_csv(infile, skiprows=firstDataLine, delim_whitespace=True)\n",
    "    filename = df.columns[1]\n",
    "    df.rename({filename: 'radiance'}, axis=1, inplace=True)\n",
    "    df['filename'] = filename\n",
    "    df['date_saved'] = date_saved\n",
    "    df['Latitude'] = lat\n",
    "    df['Longitude'] = lon\n",
    "    df['Type'] = i\n",
    "    try:\n",
    "        df['Spec_number'] = int(filename[-10:-8])\n",
    "    except ValueError:\n",
    "        df['Spec_number'] = int(filename[-6:-4])\n",
    "    df['Inst_number'] = inst\n",
    "    return df\n",
    "\n",
    "#\n",
    "### Loop through all spectrum files in \"indir\" and combine the resulting dataframes.\n",
    "#\n",
    "# For each 'line*' directory in 'indir', iterate through each file\n",
    "# ending with 'suffix' and run 'load_spectrum_to_df'. Finally,\n",
    "# return a concatenated dataframe made up of all the individual\n",
    "# dataframes.\n",
    "#\n",
    "def load_from_dir(indir, prefix, suffix):\n",
    "    all_dfs = []\n",
    "    \n",
    "    #\n",
    "    # Initalise 'spectra' list and fill with files that end in 'suffix'\n",
    "    #\n",
    "    spectra = []\n",
    "    for root, dirs, files in sorted(os.walk(indir)):\n",
    "        for file in files:\n",
    "            if file.startswith(prefix) and file.endswith(suffix):\n",
    "                spectra.append(file)\n",
    "    spectra = sorted(spectra)\n",
    "\n",
    "    for name in spectra:\n",
    "    \n",
    "        infile = indir + name\n",
    "    \n",
    "        df = load_spectrum_to_df(infile, prefix)\n",
    "        all_dfs.append(df)\n",
    "\n",
    "    return pd.concat(all_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for, and identify, unique prefixes for multiple measurements made on the same day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def unique_prefixes(indir, PreList, suffix):\n",
    "    spectra = []\n",
    "    for root, dirs, files in sorted(os.walk(indir)):\n",
    "        for file in files:\n",
    "            if any(ext in file for ext in PreList) and file.endswith(suffix):\n",
    "                spectra.append(file)\n",
    "\n",
    "    prefixes = []\n",
    "    for i in set([x[:-17] for x in spectra]):\n",
    "        prefixes.append(i)\n",
    "        \n",
    "    for pfx in prefixes:\n",
    "        spec2 = []\n",
    "        for file in spectra:\n",
    "            if file.startswith(pfx):\n",
    "                spec2.append(file)\n",
    "\n",
    "        if len(spec2) != 6:\n",
    "            if len(spec2) != 8:\n",
    "                print('Removed spectra with sub-string '+pfx+': there are '+str(len(spec2))+' spectra and NOT 6 or 8, as expected.')\n",
    "                prefixes.remove(pfx)\n",
    "        else:\n",
    "            print('Added '+str(len(spec2))+' spectra with prefix '+pfx)\n",
    "\n",
    "    return prefixes\n",
    "\n",
    "prefs = unique_prefixes(indir, PreList, suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make DataFrame for all measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_DDframe(indir, prefs, suffix):\n",
    "    \n",
    "    alldfs= []\n",
    "    \n",
    "    for i in prefs:\n",
    "        df = load_from_dir(indir, i, suffix)\n",
    "        alldfs.append(df)\n",
    "\n",
    "    return pd.concat(alldfs)\n",
    "\n",
    "alldfs = make_DDframe(indir, prefs, suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Diffuse/Direct DataFrame for one measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def DiffuseDirect(alldata):\n",
    "    \n",
    "    intdata = alldata.copy()\n",
    "    intdata.set_index('Wavelength', inplace=True)\n",
    "\n",
    "    df=pd.DataFrame()\n",
    "    for i in intdata.Spec_number.unique():\n",
    "        df[str(i)] = intdata[intdata.Spec_number==i].radiance\n",
    "\n",
    "    Direct = df[['0','1']].mean(axis=1)\n",
    "    try:\n",
    "        Helper = df[['2','3', '6', '7']].mean(axis=1)\n",
    "    except KeyError:\n",
    "        Helper = df[['2','3']].mean(axis=1)\n",
    "\n",
    "    Shade = df[['4','5']].mean(axis=1)\n",
    "    Diffuse = Direct - (Helper - Shade)\n",
    "    outdf = pd.concat([Diffuse, Direct], axis=1)\n",
    "    outdf.columns=['Diffuse', 'Direct']\n",
    "\n",
    "    return outdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot diffuse and direct spectra for each measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(9,5))\n",
    "plt.tight_layout(pad=3.5, w_pad=1.0, h_pad=1.0)\n",
    "\n",
    "leglab = []\n",
    "\n",
    "for idx, i in enumerate(prefs):\n",
    "    SingleDF = alldfs[alldfs.Type==i]\n",
    "    outdf = DiffuseDirect(SingleDF)\n",
    "    outdf.plot(ax=axes, color=colpac[idx])\n",
    "    ts = pd.to_datetime(str(alldfs[alldfs.Type==i].date_saved.unique()[0])) \n",
    "    hour = int(ts.strftime('%H'))\n",
    "    mins = ts.strftime('%M')\n",
    "    time_s = str((hour+10)%12)+':'+mins+' AEST'\n",
    "    leglab.append('Diffuse '+time_s)\n",
    "    leglab.append('Direct '+time_s)\n",
    "\n",
    "axes.legend(labels=leglab)\n",
    "axes.set_ylim(-0.02, 2.0)\n",
    "axes.set_xlim(330,2400)\n",
    "axes.set_xlabel('Wavelength (nm)')\n",
    "axes.set_ylabel('Radiance (W m$^{-2}$ nm$^{-1}$ sr$^{-1}$)')\n",
    "plt.title(field_data[0]+' '+field_data[1])\n",
    "\n",
    "newax = fig.add_axes([0.6,0.4,0.3,0.3], anchor='NE', zorder=1)\n",
    "newax.imshow(im)\n",
    "newax.axis('off')\n",
    "\n",
    "plt.savefig(outdir+'dd.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How long did this notebook take to run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(\"This Notebook took \", str(datetime.timedelta(seconds=int((time.time() - start_time)))), \"(h:m:s) to run\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
