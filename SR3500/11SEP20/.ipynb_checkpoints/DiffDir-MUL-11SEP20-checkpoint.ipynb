{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for Diffuse/Direct - Mullion - 11SEP20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "This workflow is designed such that you should only need to edit information in the first cell below.\n",
    "    \n",
    "### Input and Output directory structure\n",
    "First, choose input (indir) and output (outdir) directories. The input directory will contain the spectra, whilst the output directory will contain plots and CSVs of final spectra.\n",
    "    \n",
    "There is a specific directory structure that is required for indir. If this structure is not followed exactly, then the notebook will not run correctly. The directory structure for this example looks like:\n",
    "    \n",
    "| Level 1 directory | Level 2 directory | Level 3 directory |\n",
    "| --- | --- | --- |\n",
    "| DD1 | Direct | Mul_dd100000.asd.irr.txt|\n",
    "| \" | \" | Mul_dd100001.asd.irr.txt|\n",
    "| \" | Helper | Mul_dd100002.asd.irr.txt|\n",
    "| \" | \" | Mul_dd100003.asd.irr.txt|\n",
    "| \" | Shade | Mul_dd100004.asd.irr.txt|\n",
    "| \" | \" | Mul_dd100005.asd.irr.txt|\n",
    "| DD2 | Direct | Mul_dd_fin00000.asd.irr.txt|\n",
    "| \" | \" | Mul_dd_fin00001.asd.irr.txt|\n",
    "| \" | Helper | Mul_dd_fin00002.asd.irr.txt|\n",
    "| \" | \" | Mul_dd_fin00003.asd.irr.txt|\n",
    "| \" | Shade | Mul_dd_fin00004.asd.irr.txt|\n",
    "| \" | \" | Mul_dd_fin00005.asd.irr.txt|\n",
    "\n",
    "In words: there are two top-level directories (DD1 and DD2), corresponding to two diffuse/direct measurements. In each of these directories, the spectra have been placed into either \"Direct\", \"Helper\" or \"Shade\" subdirectories. This structure is needed by the workflow to identify the spectra correctly. \n",
    "\n",
    "It is possible that any number of direct/diffuse measurements have been carried out (not necessarily the two in this example). If, for example, there are four measurements, then create four top-level directories (DD1, DD2, DD3, DD4), with each containing the same subdirectory structure (Direct/Helper/Shade). The workflow will process however many directories appear in the top level as a different diffuse/direct measurement.\n",
    "\n",
    "### Field data information\n",
    "The \"field_data\" list should contain basic information on the location and date of the diffuse/direct measurements. The first entry is the field site three-letter-acronym (eg \"MUL\" for Mullion), the second entry is the date in DDMMMYY format.\n",
    "\n",
    "### Suffix\n",
    "Since it is possible that not all ASD spectra files have the same filename suffix, this is manually entered as \"asd.irr.txt\". Pay close attention to the full stops in this string. ie. \".asd.irr.txt\" will not work.\n",
    "\n",
    "\n",
    "Once you have all of the fields in the first cell correctly filled out, you can click on \"Kernel\" -> \"Restart & Run All\". Scroll down to the bottom to see results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Specify input and output directories below\n",
    "#\n",
    "indir = '/g/data/up71/projects/CalVal_Phase2/SR3500/11SEP20/RAW_DATA/ASD_DATA/direct_diffuse/'\n",
    "outdir = '/g/data/up71/projects/CalVal_Phase2/SR3500/11SEP20/PNGS/MUL_11SEP20_DD/'\n",
    "\n",
    "#\n",
    "# Fill out field_data below. It is in the format: 'Field Site Short Name', 'Date'.\n",
    "#\n",
    "field_data = ['MUL', '11SEP20']\n",
    "\n",
    "#\n",
    "# Assumed suffix for spectral files is defined below\n",
    "#\n",
    "suffix = 'asd.irr.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import datacube\n",
    "import sys, os, shutil, glob, subprocess\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "#\n",
    "# Use notebook format\n",
    "# Set default font size for all plots\n",
    "# Set saved figure dpi to high quality\n",
    "#\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams.update({'font.size': 12})\n",
    "matplotlib.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "#\n",
    "# Remove old files in output directory and create a new one\n",
    "#\n",
    "directory = os.path.dirname(outdir)\n",
    "if os.path.exists(directory):\n",
    "    shutil.rmtree(directory)\n",
    "os.makedirs(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\n",
    "# Colours used for plotting multi-coloured Lines\n",
    "#\n",
    "colpac=['#770000', '#FF0000', '#FF7700', '#FFFF00', '#77FF00', '#00FF00', \n",
    "        '#00FF77', '#00FFFF', '#0077FF', '#0000FF', '#000077', '#FF00FF', '#777777', '#770077', '#777700']\n",
    "\n",
    "#\n",
    "# Start Figure numbering at 1\n",
    "#\n",
    "fignum = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following cell was originally \"LoadData.py\", but brought internally so the notebook doesn't depend on anything externally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "#                                                                             #\n",
    "# Action functions are defined to retrieve specific parts of the header for   #\n",
    "# each spectrum. These functions are used in extract_metadata.                #\n",
    "#                                                                             #\n",
    "###############################################################################\n",
    "\n",
    "# Instrument Number\n",
    "def action1(l):\n",
    "    return l[27:34]\n",
    "\n",
    "# Datetime of spectrum\n",
    "def action2(l):\n",
    "    return l[16:38]\n",
    "\n",
    "# SWIR1 gain\n",
    "def action3(l):\n",
    "    return l[15:33]\n",
    "\n",
    "# SWIR2 gain\n",
    "def action4(l):\n",
    "    return l[15:33]\n",
    "\n",
    "# GPS Latitude in decimal degrees\n",
    "def action5(l):\n",
    "    return float(l[17:20])-float(l[20:27])/60\n",
    "\n",
    "# GPS Longitude in decimal degrees\n",
    "def action6(l):\n",
    "    return float(l[19:22])+float(l[22:30])/60\n",
    "\n",
    "#\n",
    "# Based on action functions defined above, extract header metadata from\n",
    "# a file.\n",
    "#\n",
    "def extract_metadata(filename):\n",
    "    strings = {\n",
    "        'instrument number': action1,\n",
    "        'Spectrum saved': action2,\n",
    "        'GPS-Latitude': action5,\n",
    "        'GPS-Longitude': action6\n",
    "    }\n",
    "\n",
    "    with open(filename) as file:\n",
    "        list_of_actions = []\n",
    "        for line in file:\n",
    "            for search, action in strings.items():\n",
    "                if search in line:\n",
    "                    list_of_actions.append(action(line))\n",
    "        return list_of_actions\n",
    "\n",
    "#\n",
    "### Extract spectrum and header information from a spectrum file. \n",
    "### Create a Pandas dataframe with the result.\n",
    "#\n",
    "def load_spectrum_to_df(infile, i):\n",
    "    \n",
    "    p1 = subprocess.Popen([\"grep\", \"-an\", \"^Wavelength\", infile], stdout=subprocess.PIPE)\n",
    "    p2 = subprocess.Popen([\"cut\", \"-d:\", \"-f\", \"1\"], stdin=p1.stdout, stdout=subprocess.PIPE)\n",
    "    p1.stdout.close()  # Allow p1 to receive a SIGPIPE if p2 exits.\n",
    "    fdl,err = p2.communicate()\n",
    "    firstDataLine = int(fdl)-1\n",
    "\n",
    "    inst, date_str, lat, lon = extract_metadata(infile)\n",
    "\n",
    "    date_saved = datetime.strptime(date_str, '%m/%d/%Y at %H:%M:%S')\n",
    "    \n",
    "    df = pd.read_csv(infile, skiprows=firstDataLine, delim_whitespace=True)\n",
    "    filename = df.columns[1]\n",
    "    df.rename({filename: 'radiance'}, axis=1, inplace=True)\n",
    "    df['filename'] = filename\n",
    "    df['date_saved'] = date_saved\n",
    "    df['Latitude'] = lat\n",
    "    df['Longitude'] = lon\n",
    "    df['Type'] = i\n",
    "    try:\n",
    "        df['Spec_number'] = int(filename[-10:-8])\n",
    "    except ValueError:\n",
    "        df['Spec_number'] = int(filename[-6:-4])\n",
    "    df['Inst_number'] = inst\n",
    "    return df\n",
    "\n",
    "#\n",
    "### Loop through all spectrum files in \"indir\" and combine the resulting dataframes.\n",
    "#\n",
    "# For each 'line*' directory in 'indir', iterate through each file\n",
    "# ending with 'suffix' and run 'load_spectrum_to_df'. Finally,\n",
    "# return a concatenated dataframe made up of all the individual\n",
    "# dataframes.\n",
    "#\n",
    "def load_from_dir(indir, suffix):\n",
    "    all_dfs = []\n",
    "\n",
    "    for i in ['Direct', 'Helper', 'Shade']:\n",
    "        home2 = indir+i+'/'\n",
    "\n",
    "        #\n",
    "        # Initalise 'spectra' list and fill with files that end in 'suffix'\n",
    "        #\n",
    "        spectra = []\n",
    "        for root, dirs, files in sorted(os.walk(home2)):\n",
    "            for file in files:\n",
    "                if file.endswith(suffix):\n",
    "                    spectra.append(file)\n",
    "        spectra = sorted(spectra)\n",
    "    \n",
    "        for name in spectra:\n",
    "    \n",
    "            infile = home2 + name\n",
    "    \n",
    "            df = load_spectrum_to_df(infile, i)\n",
    "            all_dfs.append(df)\n",
    "\n",
    "    return pd.concat(all_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def DiffuseDirect(indir, suffix):\n",
    "    \n",
    "    alldata = load_from_dir(indir, suffix)\n",
    "\n",
    "    alldata.set_index('Wavelength', inplace=True)\n",
    "\n",
    "    Drct, Hlpr, Shd = [], [], []\n",
    "    for i in alldata.index.unique():\n",
    "        Drct.append([i, alldata.radiance[np.logical_and(alldata.Type=='Direct', alldata.index==i)].mean()])\n",
    "        Hlpr.append([i, alldata.radiance[np.logical_and(alldata.Type=='Helper', alldata.index==i)].mean()])\n",
    "        Shd.append([i, alldata.radiance[np.logical_and(alldata.Type=='Shade', alldata.index==i)].mean()])\n",
    "\n",
    "    Direct = pd.DataFrame(np.array(Drct), columns=['Wavelength', 'radiance'])\n",
    "    Direct.set_index('Wavelength', inplace=True)\n",
    "    Helper = pd.DataFrame(np.array(Hlpr), columns=['Wavelength', 'radiance'])\n",
    "    Helper.set_index('Wavelength', inplace=True)\n",
    "    Shade = pd.DataFrame(np.array(Shd), columns=['Wavelength', 'radiance'])\n",
    "    Shade.set_index('Wavelength', inplace=True)\n",
    "\n",
    "    return (Direct - (Helper - Shade)), Direct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search through indir for directories and read in diffuse/direct spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dirs = glob.glob(indir+'*')\n",
    "dirs.sort()\n",
    "\n",
    "\n",
    "dif, drt = {}, {}\n",
    "for i in range(len(dirs)):\n",
    "    dif['Diffuse'+str(i)], drt['Direct'+str(i)] = DiffuseDirect(dirs[i]+'/', suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1, figsize=(9,5))\n",
    "plt.tight_layout(pad=3.5, w_pad=1.0, h_pad=1.0)\n",
    "\n",
    "leglab = []\n",
    "data = pd.DataFrame()\n",
    "\n",
    "for i in range(len(list(dif.values()))):\n",
    "    # Make DataFrame from Diffuse and Direct spectra\n",
    "    data['Diffuse'+str(i)] = pd.DataFrame(list(dif.values())[i]).radiance\n",
    "    data['Direct'+str(i)] = pd.DataFrame(list(drt.values())[i]).radiance\n",
    "    \n",
    "    # Plot Diffuse and Direct spectra\n",
    "    list(dif.values())[i].plot(ax=axes)\n",
    "    list(drt.values())[i].plot(ax=axes)\n",
    "    \n",
    "    # Create legend labels for plot\n",
    "    leglab.append(list(dif.keys())[i])\n",
    "    leglab.append(list(drt.keys())[i])\n",
    "\n",
    "axes.legend(labels=leglab)\n",
    "axes.set_ylim(-0.02, 1.5)\n",
    "axes.set_xlim(330,2220)\n",
    "axes.set_xlabel('Wavelength (nm)')\n",
    "axes.set_ylabel('Radiance (W m$^{-2}$ nm$^{-1}$ sr$^{-1}$)')\n",
    "\n",
    "plt.savefig(outdir+'dd.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How long did this notebook take to run?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(\"This Notebook took \", str(datetime.timedelta(seconds=int((time.time() - start_time)))), \"(h:m:s) to run\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
